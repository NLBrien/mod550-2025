{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089474e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nRepository: https://github.com/NLBrien/mod550-2025\\nCreation date: 2025-10-14\\nAuthor: Nathan L.Brien\\nCourse: MOD550 - Machine Learning\\nTitle: Semester project\\nDescription:    Collect all functions into one python notebook file.\\n                Functions couldn't be launched as individual file due to unknown python error.\\n                Needed to gather all sub function to one script to fix library error.\\n    Listed functions\\n    - Linear Regression (LinReg) using sklearn\\n    - Mean Squared Error (MSE) code in vanilla Python\\n    - Neural Network (NN) using keras\\n    - K-Means (KM) clustering\\n    - Gaussian (GMM) code\\nPython 3.10.9: necessary for use of tensorflow\\n\\nLast modification date: 2025-10-14\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------- INFO --------\n",
    "\"\"\"\n",
    "Repository: https://github.com/NLBrien/mod550-2025\n",
    "Creation date: 2025-10-14\n",
    "Author: Nathan L.Brien\n",
    "Course: MOD550 - Machine Learning\n",
    "Title: Semester project\n",
    "Description:    Collect all functions into one python notebook file.\n",
    "                Functions couldn't be launched as individual file due to unknown python error.\n",
    "                Needed to gather all sub-function into one script to fix library error.\n",
    "    Listed functions\n",
    "    - Linear Regression (LinReg) using sklearn\n",
    "    - Mean Squared Error (MSE) code in vanilla Python\n",
    "    - Neural Network (NN) using keras\n",
    "    - K-Means (KM) clustering\n",
    "    - Gaussian (GMM) code\n",
    "Python 3.10.9: necessary for use of tensorflow\n",
    "\n",
    "Last modification date: 2025-10-15\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb36015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- LIBRARIES --------\n",
    "\n",
    "## BASIC LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## LINEAR REGRESSION (LinReg) IMPORT\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "## MEAN SQUARED ERROR (MSE) IMPORT\n",
    "# N/A\n",
    "\n",
    "## NEURAL NETWORK (NN) IMPORT\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "## K-MEANS (KM) IMPORT\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "## GAUSSIAN MIXTURE MODEL (GMM) IMPORT\n",
    "from sklearn.mixture import GaussianMixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5486bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- LINEAR REGRESSION (LinReg) --------\n",
    "\"\"\"\n",
    "Linear Regression in simple Python (NumPy and sklearn)\n",
    "Source script: PYTHON_DEF_linearregression.py\n",
    "\n",
    "Before using this function, ensure that:\n",
    "    - The necessary library is imported (NumPy, sklearn)\n",
    "    - The data is numeric\n",
    "    - The data contains no NaN values\n",
    "Parameters:\n",
    "    LinReg_x : [array], feature data\n",
    "    LinReg_y : [array], target data\n",
    "Returns:\n",
    "    LinReg_model.coef_: [ndarray], regression coefficients\n",
    "    LinReg_model.intercept_: [float], intercept term\n",
    "    LinReg_y_pred : [ndarray], predicted values\n",
    "\"\"\"\n",
    "\n",
    "def Linear_Regression(LinReg_x, LinReg_y):\n",
    "\n",
    "    ## Assign arrays\n",
    "    x = np.array(LinReg_x, dtype=float)\n",
    "    y = np.array(LinReg_y, dtype=float)\n",
    "\n",
    "    # Reshape if data 1D instead of 2D\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "    # Initialize linear regresison model\n",
    "    LinReg_model = LinearRegression()\n",
    "\n",
    "    # Fit the model with the data\n",
    "    LinReg_model.fit(x, y)\n",
    "\n",
    "    # Predictions\n",
    "    LinReg_y_pred = LinReg_model.predict(x)\n",
    "\n",
    "    return LinReg_model.coef_, LinReg_model.intercept_, LinReg_y_pred, LinReg_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a842a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- MEAN SQUARED ERROR (MSE) --------\n",
    "\"\"\"\n",
    "Mean squared error (MSE) in vanilla Python\n",
    "Source script: PYTHON_DEF_mse.py\n",
    "\n",
    "Before using this function, run linear regression to get predictions.\n",
    "\n",
    "Before using this function, ensure that:\n",
    "    - The data is numeric (int or float)\n",
    "    - The two input lists have the same length\n",
    "    - The data contains no NaN values\n",
    "Parameters:\n",
    "    mse_observed = [list], observed values\n",
    "    mse_predicted = [list], predicted values\n",
    "Returns:\n",
    "    mse = [float], mean squared error between observed and predicted values\n",
    "\"\"\"\n",
    "\n",
    "def Mean_Squared_Error(mse_observed, mse_predicted):\n",
    "   \n",
    "\t## Validate input lengths\n",
    "    if len(mse_observed) != len(mse_predicted):\n",
    "        raise ValueError(\n",
    "            f\"The lengths of input lists are not equal: \"\n",
    "            f\"{len(mse_observed)} vs {len(mse_predicted)}\"\n",
    "        )\n",
    "\n",
    "    ## Initialize sum of squared errors\n",
    "    sum_square_error = 0\n",
    "\n",
    "    ## Loop through observations\n",
    "    for obs, pred in zip(mse_observed, mse_predicted):\n",
    "        sum_square_error += (obs - pred) ** 2\n",
    "\n",
    "    ## Calculate mean squared error\n",
    "    mse = sum_square_error / len(mse_observed)\n",
    "\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30869fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- NEURAL NETWORK (NN) --------\n",
    "\"\"\"\n",
    "Neural Network in simple Python using Keras\n",
    "Source script: PYTHON_DEF_neuralnetwork.py\n",
    "\n",
    "Before using this function, ensure that:\n",
    "    - The necessary libraries are imported (NumPy, TensorFlow/Keras)\n",
    "    - The input data is preprocessed and scaled (StandardScaler)\n",
    "    - The data is numeric\n",
    "    - The data contains no NaN values\n",
    "Parameters:\n",
    "    NN_X : [array],  Feature data\n",
    "    NN_y : [array], Target data\n",
    "    dense_1: [int], (8, 16, 64, 128), Number of neurons for layer 1 (default = 8)\n",
    "    dense_2: [int], (8, 16, 64, 128), Number of neurons for layer 2 (default = 64)\n",
    "    activate_fnc: [str], (\"relu\", \"tanh\", \"sigmoid\", \"elu\"), Activating function for regression output (default = \"relu\")\n",
    "    kernel_reg: [import], (l1, l2, l1_l2), Regularizing function for training (default = l2(0.01))\n",
    "    optimize_fnc: [str], (\"SGD\", \"Adagrad\", \"RMSProp\", \"Adam\", \"AdamW\", \"Nadam\", \"Adadelta\")\n",
    "        Optimizing function strategy, a.k.a. algorithm (default = \"adam\")\n",
    "    epochs_nb : [int], Number of training epochs (default = 20)\n",
    "Returns:\n",
    "    NN_model : The trained neural network model\n",
    "    NN_y_pred : [ndarray], Predicted values for the input X\n",
    "    NN_final_loss: [float], final training loss value\n",
    "    NN_mse: [float], mean squared error\n",
    "    NN_mean_pred: [float], average of all predictions\n",
    "\"\"\"\n",
    "\n",
    "def Neural_Network(NN_x,\n",
    "                   NN_y,\n",
    "                   dense_1 = 8,\n",
    "                   dense_2 = 64,\n",
    "                   activate_fnc = \"relu\",\n",
    "                   kernel_reg = l2(0.01),\n",
    "                   optimize_fnc = \"adam\",\n",
    "                   epochs_nb = 20, \n",
    "                   ):\n",
    "    # Turn input values to numpy arrays\n",
    "    x = np.array(NN_x, dtype=float)\n",
    "    y = np.array(NN_y, dtype=float)\n",
    "\n",
    "    # Reshape if data 1D instead of 2D\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "    # Define neural network model for linear regression\n",
    "    NN_model = Sequential([\n",
    "        Dense(dense_1, input_dim = NN_x.shape[1], activation = activate_fnc, kernel_regularizer = kernel_reg),\n",
    "        Dense(dense_2, activation = activate_fnc, kernel_regularizer = kernel_reg),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Complete the model\n",
    "    NN_model.compile(optimizer = optimize_fnc, loss = \"mse\")\n",
    "\n",
    "    # Train the model\n",
    "    history = NN_model.fit(x, y, epochs = epochs_nb, verbose = 0)\n",
    "\n",
    "    # Use the model for prediction\n",
    "    NN_y_pred = NN_model.predict(x)\n",
    "\n",
    "    # Compute result metrics\n",
    "    \"\"\"\n",
    "    Use of AI (Microsoft Copilot version 1.25091.124.0) to impliment metrics solution\n",
    "    \"\"\"\n",
    "    ## final loss\n",
    "    NN_final_loss = history.history['loss'][-1] if 'loss' in history.history else None\n",
    "    ## mse\n",
    "    NN_mse = Mean_Squared_Error(mse_observed = y, mse_predicted = NN_y_pred)\n",
    "    ## mean prediction\n",
    "    NN_mean_pred = float(np.mean(NN_y_pred))\n",
    "\n",
    "    return NN_model, NN_y_pred, NN_final_loss, NN_mse, NN_mean_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- K-MEANS (KM) --------\n",
    "\"\"\"\n",
    "K-Means clustering in simple Python using sklearn\n",
    "\n",
    "Before using this function, ensure that:\n",
    "    - The necessary libraries are imported (NumPy, scikit-learn, matplotlib for visualization)\n",
    "    - The input data is numeric\n",
    "    - The data contains no NaN values\n",
    "K_Means_Elbow(KM_x, KM_y):\n",
    "    Parameters:\n",
    "        KM_x : [array], Feature data\n",
    "        KM_y : [array], Target-like data\n",
    "    Returns:\n",
    "        KME_labels: [ndarray], shape (n_samples,), cluster assignment for each point\n",
    "        KME_centers: [ndarray], shape (n_clusters, n_features), cluster centroids\n",
    "        KME_inertia: [float], sum of squared distances of samples to their closest cluster center\n",
    "        KME_model: [KMeans object], the trained KMeans model\n",
    "K_Means_Optimal(KM_x, KM_y, cluster_nb=3, RSEED=42):\n",
    "    Parameters:\n",
    "        KM_x : [array], Feature data\n",
    "        KM_y : [array], Target-like data\n",
    "        cluster_nb : [int], Number of clusters to form (default = 3)\n",
    "        RSEED : [int], Random seed for reproducibility (default = 42)\n",
    "    Returns:\n",
    "        KMO_labels: [ndarray], shape (n_samples,), cluster assignment for each point\n",
    "        KMO_centers: [ndarray], shape (n_clusters, n_features), cluster centroids\n",
    "        KMO_inertia: [float], sum of squared distances of samples to their closest cluster center\n",
    "        KMO_model: [KMeans object], the trained KMeans model\n",
    "\"\"\"\n",
    "def K_Means_Elbow(KM_x, KM_y):\n",
    "    \n",
    "    # Turn input values to numpy arrays\n",
    "    x = np.array(KM_x, dtype=float)\n",
    "    y = np.array(KM_y, dtype=float)\n",
    "\n",
    "    # Reshape if data 1D instead of 2D\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "    # Combine x and y into a single dataset for clustering\n",
    "    data = np.column_stack((x, y))\n",
    "\n",
    "    # Initialize and fit KMeans model\n",
    "    inertias = []\n",
    "\n",
    "    # Run KMeans for a range of cluster numbers to visualize the elbow method\n",
    "    for i in range(1, 11):\n",
    "        kmeans = KMeans(n_clusters = i, random_state = 42)\n",
    "        kmeans.fit(data)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "\n",
    "    # Plot the elbow method\n",
    "    plt.plot(range(1, 11), inertias, marker='o')\n",
    "    plt.title(\"K-Means elbow method\\n(optimal clusters)\")\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Inertia\")\n",
    "    plt.show()\n",
    "\n",
    "    return kmeans.labels_, kmeans.cluster_centers_, kmeans.inertia_, kmeans\n",
    "\n",
    "def K_Means_Optimal(KM_x, KM_y, cluster_nb = 3, RSEED = 42):\n",
    "    \n",
    "    # Turn input values to numpy arrays\n",
    "    x = np.array(KM_x, dtype=float)\n",
    "    y = np.array(KM_y, dtype=float)\n",
    "\n",
    "    # Reshape if data 1D instead of 2D\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "    # Combine x and y into a single dataset for clustering\n",
    "    data = np.column_stack((x, y))\n",
    "\n",
    "    # Initialize and fit KMeans model\n",
    "    kmeans = KMeans(n_clusters = cluster_nb, random_state = RSEED)\n",
    "\n",
    "    # Fit the model with the data\n",
    "    kmeans.fit(data)\n",
    "\n",
    "    return kmeans.labels_, kmeans.cluster_centers_, kmeans.inertia_, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- GAUSSIAN MIXTURE MODEL (GMM) --------\n",
    "\"\"\"\n",
    "Gaussian Mixture Model (GMM) in simple Python using sklearn\n",
    "\n",
    "Before using this function, ensure that:\n",
    "    - The necessary libraries are imported (NumPy, sklearn)\n",
    "    - The input data is numeric\n",
    "    - The data contains no NaN values\n",
    "Parameters:\n",
    "    GMM_x : [array], Feature data (1D or 2D)\n",
    "    component_nb : [int], Number of Gaussian components (clusters) to fit (default = 2)\n",
    "    RSEED : [int], Random seed for reproducibility (default = 42)\n",
    "Returns:\n",
    "    GMM_labels : [ndarray], cluster assignment for each point\n",
    "    GMM_probs : [ndarray], soft probabilities of belonging to each cluster\n",
    "    GMM_means : [ndarray], estimated Gaussian means\n",
    "    GMM_covariances : [ndarray], covariance matrices of each Gaussian component\n",
    "    GMM_model : [GaussianMixture object], the trained GMM model\n",
    "\"\"\"\n",
    "def Gaussian_Mixture_Model(GMM_x, component_nb = 2, RSEED = 42):\n",
    "    \n",
    "    # Turn input values to numpy arrays\n",
    "    x = np.array(GMM_x, dtype=float)\n",
    "    \n",
    "    # Reshape \"x\" if data 1D instead of 2D\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "\n",
    "    # Initialize and fit Gaussian Mixture Model\n",
    "    gmm = GaussianMixture(n_components = component_nb, random_state=RSEED)\n",
    "    gmm.fit(x)\n",
    "\n",
    "    # Predict hard labels and soft probabilities\n",
    "    labels = gmm.predict(x)\n",
    "    probs = gmm.predict_proba(x)\n",
    "\n",
    "    return labels, probs, gmm.means_, gmm.covariances_, gmm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
